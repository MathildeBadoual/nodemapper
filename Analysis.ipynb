{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hobbs/.local/lib/python3.6/site-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "/home/hobbs/.local/lib/python3.6/site-packages/ggplot/stats/smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "from sklearn import preprocessing, linear_model, model_selection, ensemble, metrics\n",
    "from ggplot import *\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to import our data. I'm going to import it once from the csv, and create a pickle below. However, when I re-run this notebook I want to be able to skip steps, so I'll just load the pickle. That is much faster. The argument `quick=False` will force the program to re-create the pickle (for example if we change the csv data or add new variables to the load_data function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(quick=True):\n",
    "    \n",
    "    def make_pickle():\n",
    "        # Read csv\n",
    "        df = pd.read_csv('nodes_final_data.csv')\n",
    "        \n",
    "        # Set the index\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df = df.set_index(['node', 'time'])\n",
    "\n",
    "        # Create/ format some variables\n",
    "        df['week'] = [value[1].isocalendar()[1] for value in df.index.values]\n",
    "\n",
    "        # Save as a pickle\n",
    "        df.to_pickle('nodes_final_data.p')\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    if quick == True:\n",
    "        try:\n",
    "            print(\"Trying to open saved data.\")\n",
    "            with open('nodes_final_data.p', 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(\"No existing pickle found... picklemaking!\")\n",
    "            return make_pickle()\n",
    "    else:\n",
    "        print(\"Pickling a fresh new pickle.\")\n",
    "        return make_pickle()\n",
    "\n",
    "def load_subset(n, df):\n",
    "    print(\"Loading a subset with \", n, \" nodes.\")\n",
    "    np.random.seed(seed=1)\n",
    "    node_ids = df.index.get_level_values('node').unique()\n",
    "    selected_nodes = list(np.random.choice(node_ids, size = n))\n",
    "    return df.loc[selected_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to open saved data.\n",
      "Loading a subset with  100  nodes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hr</th>\n",
       "      <th>opr_hr</th>\n",
       "      <th>day</th>\n",
       "      <th>dollar_mw</th>\n",
       "      <th>other_MW</th>\n",
       "      <th>solar_MW</th>\n",
       "      <th>wind_MW</th>\n",
       "      <th>load_MW</th>\n",
       "      <th>fuel_price</th>\n",
       "      <th>net_exp_MW</th>\n",
       "      <th>temp</th>\n",
       "      <th>irrad</th>\n",
       "      <th>wind_u</th>\n",
       "      <th>wind_v</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ALAMT4G_7_B1</th>\n",
       "      <th>2017-05-02 00:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>30.549540</td>\n",
       "      <td>13091.870117</td>\n",
       "      <td>6837.720215</td>\n",
       "      <td>1992.119995</td>\n",
       "      <td>28981.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-8073.870117</td>\n",
       "      <td>292.096466</td>\n",
       "      <td>294.044172</td>\n",
       "      <td>2.531747</td>\n",
       "      <td>1.636286</td>\n",
       "      <td>33.765897</td>\n",
       "      <td>-118.103607</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-02 01:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>47.267689</td>\n",
       "      <td>17182.660156</td>\n",
       "      <td>2931.449951</td>\n",
       "      <td>2254.040039</td>\n",
       "      <td>29669.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-8380.599609</td>\n",
       "      <td>292.121277</td>\n",
       "      <td>294.037069</td>\n",
       "      <td>2.531789</td>\n",
       "      <td>1.636183</td>\n",
       "      <td>33.765897</td>\n",
       "      <td>-118.103607</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-02 02:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>71.159882</td>\n",
       "      <td>19997.630859</td>\n",
       "      <td>264.540009</td>\n",
       "      <td>2461.199951</td>\n",
       "      <td>29458.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-8663.000000</td>\n",
       "      <td>292.146118</td>\n",
       "      <td>294.029965</td>\n",
       "      <td>2.531830</td>\n",
       "      <td>1.636081</td>\n",
       "      <td>33.765897</td>\n",
       "      <td>-118.103607</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-02 03:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>66.884888</td>\n",
       "      <td>19904.410156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2499.290039</td>\n",
       "      <td>30325.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-8644.000000</td>\n",
       "      <td>292.170959</td>\n",
       "      <td>294.022861</td>\n",
       "      <td>2.531872</td>\n",
       "      <td>1.635978</td>\n",
       "      <td>33.765897</td>\n",
       "      <td>-118.103607</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-02 04:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>48.442291</td>\n",
       "      <td>17607.289062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2473.360107</td>\n",
       "      <td>29429.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-8591.799805</td>\n",
       "      <td>292.195801</td>\n",
       "      <td>294.015758</td>\n",
       "      <td>2.531913</td>\n",
       "      <td>1.635875</td>\n",
       "      <td>33.765897</td>\n",
       "      <td>-118.103607</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  year  month  date  hr  opr_hr  day  \\\n",
       "node         time                                                      \n",
       "ALAMT4G_7_B1 2017-05-02 00:00:00  2017      5     1   0      18    2   \n",
       "             2017-05-02 01:00:00  2017      5     1   1      19    2   \n",
       "             2017-05-02 02:00:00  2017      5     1   2      20    2   \n",
       "             2017-05-02 03:00:00  2017      5     1   3      21    2   \n",
       "             2017-05-02 04:00:00  2017      5     1   4      22    2   \n",
       "\n",
       "                                  dollar_mw      other_MW     solar_MW  \\\n",
       "node         time                                                        \n",
       "ALAMT4G_7_B1 2017-05-02 00:00:00  30.549540  13091.870117  6837.720215   \n",
       "             2017-05-02 01:00:00  47.267689  17182.660156  2931.449951   \n",
       "             2017-05-02 02:00:00  71.159882  19997.630859   264.540009   \n",
       "             2017-05-02 03:00:00  66.884888  19904.410156     0.000000   \n",
       "             2017-05-02 04:00:00  48.442291  17607.289062     0.000000   \n",
       "\n",
       "                                      wind_MW  load_MW  fuel_price  \\\n",
       "node         time                                                    \n",
       "ALAMT4G_7_B1 2017-05-02 00:00:00  1992.119995  28981.0        2.83   \n",
       "             2017-05-02 01:00:00  2254.040039  29669.0        2.83   \n",
       "             2017-05-02 02:00:00  2461.199951  29458.0        2.83   \n",
       "             2017-05-02 03:00:00  2499.290039  30325.0        2.83   \n",
       "             2017-05-02 04:00:00  2473.360107  29429.0        2.83   \n",
       "\n",
       "                                   net_exp_MW        temp       irrad  \\\n",
       "node         time                                                       \n",
       "ALAMT4G_7_B1 2017-05-02 00:00:00 -8073.870117  292.096466  294.044172   \n",
       "             2017-05-02 01:00:00 -8380.599609  292.121277  294.037069   \n",
       "             2017-05-02 02:00:00 -8663.000000  292.146118  294.029965   \n",
       "             2017-05-02 03:00:00 -8644.000000  292.170959  294.022861   \n",
       "             2017-05-02 04:00:00 -8591.799805  292.195801  294.015758   \n",
       "\n",
       "                                    wind_u    wind_v   latitude   longitude  \\\n",
       "node         time                                                             \n",
       "ALAMT4G_7_B1 2017-05-02 00:00:00  2.531747  1.636286  33.765897 -118.103607   \n",
       "             2017-05-02 01:00:00  2.531789  1.636183  33.765897 -118.103607   \n",
       "             2017-05-02 02:00:00  2.531830  1.636081  33.765897 -118.103607   \n",
       "             2017-05-02 03:00:00  2.531872  1.635978  33.765897 -118.103607   \n",
       "             2017-05-02 04:00:00  2.531913  1.635875  33.765897 -118.103607   \n",
       "\n",
       "                                  week  \n",
       "node         time                       \n",
       "ALAMT4G_7_B1 2017-05-02 00:00:00    18  \n",
       "             2017-05-02 01:00:00    18  \n",
       "             2017-05-02 02:00:00    18  \n",
       "             2017-05-02 03:00:00    18  \n",
       "             2017-05-02 04:00:00    18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_subset(100, load_data())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to expand our data into more features. Patsy is good at this, but like the above, it is time consuming to do it repeatedly. Thus, we'll save the results and only recreate them if something changes. The only downside of this is potential proliferation of pickle-matrices - gotta delete these occassionally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_patsy(arg, input_data, quick=True):\n",
    "     #File will save with the patsy description and number of observations\n",
    "    filename = arg + str(input_data.shape[1]) + '.p'\n",
    "    if quick:\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                y, X = pickle.load(f)\n",
    "        except FileNotFoundError:\n",
    "            with open(filename, 'wb') as f:\n",
    "                y, X = tuple(np.array(matrix) for matrix in patsy.dmatrices(arg, data = input_data))\n",
    "                pickle.dump((y, X), f)\n",
    "    else:\n",
    "        with open(filename, 'wb') as f:\n",
    "                y, X = tuple(np.array(matrix) for matrix in patsy.dmatrices(arg, data = input_data))\n",
    "                pickle.dump((y, X), f)\n",
    "                \n",
    "    y = np.array(y)\n",
    "    X = np.array(X)\n",
    "    return (y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to create time and spatial lags. To do that, we can use `shift()` in combination with `groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing price\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hr</th>\n",
       "      <th>opr_hr</th>\n",
       "      <th>day</th>\n",
       "      <th>dollar_mw</th>\n",
       "      <th>other_MW</th>\n",
       "      <th>solar_MW</th>\n",
       "      <th>wind_MW</th>\n",
       "      <th>...</th>\n",
       "      <th>lag158</th>\n",
       "      <th>lag159</th>\n",
       "      <th>lag160</th>\n",
       "      <th>lag161</th>\n",
       "      <th>lag162</th>\n",
       "      <th>lag163</th>\n",
       "      <th>lag164</th>\n",
       "      <th>lag165</th>\n",
       "      <th>lag166</th>\n",
       "      <th>lag167</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ALAMT4G_7_B1</th>\n",
       "      <th>2017-05-09 00:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>32.478378</td>\n",
       "      <td>14447.700195</td>\n",
       "      <td>5280.080078</td>\n",
       "      <td>722.780029</td>\n",
       "      <td>...</td>\n",
       "      <td>17.720961</td>\n",
       "      <td>12.146050</td>\n",
       "      <td>24.534060</td>\n",
       "      <td>27.252560</td>\n",
       "      <td>33.477322</td>\n",
       "      <td>36.006779</td>\n",
       "      <td>48.442291</td>\n",
       "      <td>66.884888</td>\n",
       "      <td>71.159882</td>\n",
       "      <td>47.267689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-09 01:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>45.811298</td>\n",
       "      <td>17177.009766</td>\n",
       "      <td>2384.699951</td>\n",
       "      <td>1037.520020</td>\n",
       "      <td>...</td>\n",
       "      <td>27.224449</td>\n",
       "      <td>17.720961</td>\n",
       "      <td>12.146050</td>\n",
       "      <td>24.534060</td>\n",
       "      <td>27.252560</td>\n",
       "      <td>33.477322</td>\n",
       "      <td>36.006779</td>\n",
       "      <td>48.442291</td>\n",
       "      <td>66.884888</td>\n",
       "      <td>71.159882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-09 02:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>66.499413</td>\n",
       "      <td>20402.220703</td>\n",
       "      <td>220.619995</td>\n",
       "      <td>1573.640015</td>\n",
       "      <td>...</td>\n",
       "      <td>39.247700</td>\n",
       "      <td>27.224449</td>\n",
       "      <td>17.720961</td>\n",
       "      <td>12.146050</td>\n",
       "      <td>24.534060</td>\n",
       "      <td>27.252560</td>\n",
       "      <td>33.477322</td>\n",
       "      <td>36.006779</td>\n",
       "      <td>48.442291</td>\n",
       "      <td>66.884888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-09 03:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>67.674500</td>\n",
       "      <td>20218.810547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1875.969971</td>\n",
       "      <td>...</td>\n",
       "      <td>51.065639</td>\n",
       "      <td>39.247700</td>\n",
       "      <td>27.224449</td>\n",
       "      <td>17.720961</td>\n",
       "      <td>12.146050</td>\n",
       "      <td>24.534060</td>\n",
       "      <td>27.252560</td>\n",
       "      <td>33.477322</td>\n",
       "      <td>36.006779</td>\n",
       "      <td>48.442291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-09 04:00:00</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>48.831501</td>\n",
       "      <td>17610.689453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2143.800049</td>\n",
       "      <td>...</td>\n",
       "      <td>39.964081</td>\n",
       "      <td>51.065639</td>\n",
       "      <td>39.247700</td>\n",
       "      <td>27.224449</td>\n",
       "      <td>17.720961</td>\n",
       "      <td>12.146050</td>\n",
       "      <td>24.534060</td>\n",
       "      <td>27.252560</td>\n",
       "      <td>33.477322</td>\n",
       "      <td>36.006779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  year  month  date  hr  opr_hr  day  \\\n",
       "node         time                                                      \n",
       "ALAMT4G_7_B1 2017-05-09 00:00:00  2017      5     8   0      18    2   \n",
       "             2017-05-09 01:00:00  2017      5     8   1      19    2   \n",
       "             2017-05-09 02:00:00  2017      5     8   2      20    2   \n",
       "             2017-05-09 03:00:00  2017      5     8   3      21    2   \n",
       "             2017-05-09 04:00:00  2017      5     8   4      22    2   \n",
       "\n",
       "                                  dollar_mw      other_MW     solar_MW  \\\n",
       "node         time                                                        \n",
       "ALAMT4G_7_B1 2017-05-09 00:00:00  32.478378  14447.700195  5280.080078   \n",
       "             2017-05-09 01:00:00  45.811298  17177.009766  2384.699951   \n",
       "             2017-05-09 02:00:00  66.499413  20402.220703   220.619995   \n",
       "             2017-05-09 03:00:00  67.674500  20218.810547     0.000000   \n",
       "             2017-05-09 04:00:00  48.831501  17610.689453     0.000000   \n",
       "\n",
       "                                      wind_MW    ...         lag158  \\\n",
       "node         time                                ...                  \n",
       "ALAMT4G_7_B1 2017-05-09 00:00:00   722.780029    ...      17.720961   \n",
       "             2017-05-09 01:00:00  1037.520020    ...      27.224449   \n",
       "             2017-05-09 02:00:00  1573.640015    ...      39.247700   \n",
       "             2017-05-09 03:00:00  1875.969971    ...      51.065639   \n",
       "             2017-05-09 04:00:00  2143.800049    ...      39.964081   \n",
       "\n",
       "                                     lag159     lag160     lag161     lag162  \\\n",
       "node         time                                                              \n",
       "ALAMT4G_7_B1 2017-05-09 00:00:00  12.146050  24.534060  27.252560  33.477322   \n",
       "             2017-05-09 01:00:00  17.720961  12.146050  24.534060  27.252560   \n",
       "             2017-05-09 02:00:00  27.224449  17.720961  12.146050  24.534060   \n",
       "             2017-05-09 03:00:00  39.247700  27.224449  17.720961  12.146050   \n",
       "             2017-05-09 04:00:00  51.065639  39.247700  27.224449  17.720961   \n",
       "\n",
       "                                     lag163     lag164     lag165     lag166  \\\n",
       "node         time                                                              \n",
       "ALAMT4G_7_B1 2017-05-09 00:00:00  36.006779  48.442291  66.884888  71.159882   \n",
       "             2017-05-09 01:00:00  33.477322  36.006779  48.442291  66.884888   \n",
       "             2017-05-09 02:00:00  27.252560  33.477322  36.006779  48.442291   \n",
       "             2017-05-09 03:00:00  24.534060  27.252560  33.477322  36.006779   \n",
       "             2017-05-09 04:00:00  12.146050  24.534060  27.252560  33.477322   \n",
       "\n",
       "                                     lag167  \n",
       "node         time                            \n",
       "ALAMT4G_7_B1 2017-05-09 00:00:00  47.267689  \n",
       "             2017-05-09 01:00:00  71.159882  \n",
       "             2017-05-09 02:00:00  66.884888  \n",
       "             2017-05-09 03:00:00  48.442291  \n",
       "             2017-05-09 04:00:00  36.006779  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize = lambda x: (x - np.mean(x))/ np.std(x)\n",
    "\n",
    "def lag_var(df, var, n_periods):\n",
    "    return df[var].groupby(level='node').shift(n_periods)\n",
    "\n",
    "df['temp_last_hr'] = lag_var(df, 'temp', 1)\n",
    "df['price_last_hr'] = lag_var(df, 'dollar_mw', 1)\n",
    "df['price_yesterday'] = lag_var(df, 'dollar_mw', 24)\n",
    "df['price_last_week'] = lag_var(df, 'dollar_mw', 24 * 7)\n",
    "df['nodenorm_temp'] = df['temp'].groupby(level = 'node').apply(normalize)\n",
    "df['node'] = [value[0] for value in df.index.values]\n",
    "print(\"Normalizing price\")\n",
    "\n",
    "lagnames = ''\n",
    "\n",
    "for i in list(range(1, 24 * 7)):\n",
    "    name = 'lag' + str(i)\n",
    "    lagnames += name + ' + '\n",
    "    df[name] = lag_var(df, 'dollar_mw', i)\n",
    "\n",
    "# temperature bins\n",
    "#bins = [np.min(df['nodenorm_temp']), -2, -1, 1, 2, np.max(df['nodenorm_temp'])]\n",
    "#group_names = ['Very Low', 'Low', 'Normal', 'High', 'Very High']\n",
    "#df['temp_bin'] = pd.cut(df['nodenorm_temp'], bins, labels=group_names)\n",
    "\n",
    "# drop NA values, since beginning and ends now lack variables\n",
    "df = df.dropna()\n",
    "\n",
    "# normalize features\n",
    "#to_normalize = ['other_MW', 'solar_MW', 'wind_MW', 'latitude', 'longitude', 'temp']\n",
    "#df[to_normalize] = df[to_nbormalize].apply(normalize)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to hold out a true test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['day']  = [date.isocalendar()[1] for date in df.index.get_level_values('time')]\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "# select 10 random test days\n",
    "test_days = list(np.random.choice(df['week'].unique(), size = 2))\n",
    "\n",
    "# create test set\n",
    "df_test = df[df['week'].isin(test_weeks)]\n",
    "\n",
    "#create training set\n",
    "df = df[~df['week'].isin(test_weeks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is designed to run models and record the same results for all of them. Changing the code here will change how all models are run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_hat):\n",
    "    return np.sqrt(np.mean(np.power(np.subtract(y, y_hat), 2)))\n",
    "\n",
    "def wmae(little_df, df):\n",
    "    # name is wrong as an artifact of how the thing was produced\n",
    "    little_df = little_df.rename(columns={'dollar_mw': 'error'})\n",
    "    # merge with prices\n",
    "    little_df = pd.merge(little_df, df, left_index=True, right_index=True)\n",
    "    \n",
    "    # Get absolute value of the error\n",
    "    little_df['abs_error'] = np.absolute(little_df['error'])\n",
    "    # Get week index for grouping\n",
    "    little_df['week']  = [date.isocalendar()[1] for date in little_df.index.get_level_values('time')]\n",
    "    return little_df.groupby('week').mean()['abs_error']/little_df.groupby('week').mean()['dollar_mw']\n",
    "\n",
    "def evaluate(train_index, test_index, model, X, y):\n",
    "    # Split into train and test\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Save indices from y\n",
    "    index_values = y_test.index\n",
    "    \n",
    "    fitted = model.fit(X_train, np.ravel(y_train))\n",
    "    # Calculate y_hats and map to indices\n",
    "    y_hat = pd.DataFrame(data = fitted.predict(X_test), index = index_values)\n",
    "    errors = np.subtract(y_test, y_hat)\n",
    "    y_hat_all = fitted.predict(X)\n",
    "    return [rmse(y_test, y_hat),  y_hat, errors]\n",
    "\n",
    "def run_models(models, feature_sets, df, folds=8, parallel=True):\n",
    "    '''\n",
    "    Takes a list of models and features, and runs each model with each set of features\n",
    "    Features should be patsy-formatted strings. \n",
    "    \n",
    "    Models should be a list of sci-kit learn models and the second\n",
    "    the number of jobs that used for cross-validation.\n",
    "    \n",
    "    Data is 'df' (a pandas dataframe), and 'folds' is the number of folds that should be used\n",
    "    for cross-validation.\n",
    "    '''\n",
    "    #iterate through all the models\n",
    "    results = []\n",
    "    error_list = []\n",
    "    kf = model_selection.KFold(n_splits=folds)\n",
    "    for features in tqdm_notebook(feature_sets, desc = 'Feature Set'):\n",
    "        y, X = patsy.dmatrices(features, data=df, return_type = 'dataframe')\n",
    "        # Normalize X\n",
    "        X = preprocessing.scale(X)\n",
    "        for model in tqdm_notebook(models, desc = \"Models\"):\n",
    "            if parallel:\n",
    "                result = Parallel(n_jobs=folds)(delayed(evaluate)(train_index, test_index, model, X, y) for train_index, test_index in kf.split(X))\n",
    "            else:\n",
    "                result = [evaluate(train_index, test_index, model, X, y) for train_index, test_index in kf.split(X)]\n",
    "            scores = [res[0] for res in result]\n",
    "            errors = [res[2] for res in result]\n",
    "            y_hat =  [res[1] for res in result]\n",
    "            results.append({'model': model, \n",
    "                            'features': features, \n",
    "                            'score': np.mean(scores)})\n",
    "            error_list.append(errors)\n",
    "        \n",
    "    return {'results': pd.DataFrame(results), 'errors': error_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since linear models have to be linear, it makes sense to run them with different (larger) sets of features. For example, adding squared and interaction terms makes more sense. A random forest could achieve this kind of linearity without being given the transformed variables, so there's no need to provide it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1666cdfff0d146f18976ec8bc3f8f314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Feature Set', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ddec6e8775456b9245311a520f0825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Models', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-252:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hobbs/.conda/envs/ugh/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/hobbs/.local/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/hobbs/.conda/envs/ugh/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357b0cb8d45e45718f4cefd49e9d5e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Models', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6befb05884b4426970ee45b26022737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Models', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/hobbs/.conda/envs/ugh/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ols = [linear_model.LinearRegression(fit_intercept=True, n_jobs = 3)]\n",
    "\n",
    "#generate a huge list of different elastic nets\n",
    "elastic_nets = [linear_model.ElasticNet(alpha= a, l1_ratio = l, warm_start = True)\n",
    "                for a, l in list(itertools.product(np.linspace(0.5, 1, num = 3), np.linspace(0,1, num = 3)))]\n",
    "\n",
    "feature_ideas = ['dollar_mw ~ price_last_hr + price_yesterday + price_last_week',\n",
    "                 'dollar_mw ~ C(node) + price_last_hr + price_yesterday + price_last_week + week + np.power(week,2) + solar_MW + wind_MW + latitude + longitude',\n",
    "                 'dollar_mw ~ C(node) + price_last_hr + price_yesterday + price_last_week + week + np.power(week,2) + solar_MW + wind_MW + temp + np.power(temp,2) + np.power(temp,3) + latitude + longitude']\n",
    "\n",
    "linear_results = run_models(ols + elastic_nets, feature_ideas, df, folds=4, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the weekly mean average error (WMAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>wmae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>1.984488e+01</td>\n",
       "      <td>1.558057e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>ElasticNet(alpha=0.5, copy_X=True, fit_interce...</td>\n",
       "      <td>2.126031e+01</td>\n",
       "      <td>1.826296e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>ElasticNet(alpha=0.5, copy_X=True, fit_interce...</td>\n",
       "      <td>2.040441e+01</td>\n",
       "      <td>1.682655e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>ElasticNet(alpha=0.5, copy_X=True, fit_interce...</td>\n",
       "      <td>1.985613e+01</td>\n",
       "      <td>1.576113e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>ElasticNet(alpha=0.75, copy_X=True, fit_interc...</td>\n",
       "      <td>2.221879e+01</td>\n",
       "      <td>1.982394e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>ElasticNet(alpha=0.75, copy_X=True, fit_interc...</td>\n",
       "      <td>2.088021e+01</td>\n",
       "      <td>1.769070e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>ElasticNet(alpha=0.75, copy_X=True, fit_interc...</td>\n",
       "      <td>1.987007e+01</td>\n",
       "      <td>1.587910e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>ElasticNet(alpha=1.0, copy_X=True, fit_interce...</td>\n",
       "      <td>2.313768e+01</td>\n",
       "      <td>2.130118e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>ElasticNet(alpha=1.0, copy_X=True, fit_interce...</td>\n",
       "      <td>2.139897e+01</td>\n",
       "      <td>1.857998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dollar_mw ~ price_last_hr + price_yesterday + ...</td>\n",
       "      <td>ElasticNet(alpha=1.0, copy_X=True, fit_interce...</td>\n",
       "      <td>1.988953e+01</td>\n",
       "      <td>1.601693e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>7.190229e+13</td>\n",
       "      <td>9.004051e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.5, copy_X=True, fit_interce...</td>\n",
       "      <td>2.118860e+01</td>\n",
       "      <td>1.781246e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.5, copy_X=True, fit_interce...</td>\n",
       "      <td>2.031463e+01</td>\n",
       "      <td>1.637479e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.5, copy_X=True, fit_interce...</td>\n",
       "      <td>1.977227e+01</td>\n",
       "      <td>1.539815e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.75, copy_X=True, fit_interc...</td>\n",
       "      <td>2.214457e+01</td>\n",
       "      <td>1.934547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.75, copy_X=True, fit_interc...</td>\n",
       "      <td>2.079269e+01</td>\n",
       "      <td>1.723273e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.75, copy_X=True, fit_interc...</td>\n",
       "      <td>1.979403e+01</td>\n",
       "      <td>1.550185e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=1.0, copy_X=True, fit_interce...</td>\n",
       "      <td>2.305430e+01</td>\n",
       "      <td>2.076888e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=1.0, copy_X=True, fit_interce...</td>\n",
       "      <td>2.131282e+01</td>\n",
       "      <td>1.814250e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=1.0, copy_X=True, fit_interce...</td>\n",
       "      <td>1.982448e+01</td>\n",
       "      <td>1.566591e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>6.350138e+13</td>\n",
       "      <td>1.168736e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.5, copy_X=True, fit_interce...</td>\n",
       "      <td>2.123782e+01</td>\n",
       "      <td>1.774894e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.5, copy_X=True, fit_interce...</td>\n",
       "      <td>2.032999e+01</td>\n",
       "      <td>1.629856e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.5, copy_X=True, fit_interce...</td>\n",
       "      <td>1.977227e+01</td>\n",
       "      <td>1.539815e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.75, copy_X=True, fit_interc...</td>\n",
       "      <td>2.217338e+01</td>\n",
       "      <td>1.898834e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.75, copy_X=True, fit_interc...</td>\n",
       "      <td>2.080951e+01</td>\n",
       "      <td>1.701025e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=0.75, copy_X=True, fit_interc...</td>\n",
       "      <td>1.979403e+01</td>\n",
       "      <td>1.550185e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=1.0, copy_X=True, fit_interce...</td>\n",
       "      <td>2.304178e+01</td>\n",
       "      <td>2.010951e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=1.0, copy_X=True, fit_interce...</td>\n",
       "      <td>2.132340e+01</td>\n",
       "      <td>1.775764e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dollar_mw ~ C(node) + price_last_hr + price_ye...</td>\n",
       "      <td>ElasticNet(alpha=1.0, copy_X=True, fit_interce...</td>\n",
       "      <td>1.982448e+01</td>\n",
       "      <td>1.566591e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  \\\n",
       "0   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "1   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "2   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "3   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "4   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "5   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "6   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "7   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "8   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "9   dollar_mw ~ price_last_hr + price_yesterday + ...   \n",
       "10  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "11  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "12  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "13  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "14  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "15  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "16  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "17  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "18  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "19  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "20  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "21  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "22  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "23  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "24  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "25  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "26  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "27  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "28  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "29  dollar_mw ~ C(node) + price_last_hr + price_ye...   \n",
       "\n",
       "                                                model         score  \\\n",
       "0   LinearRegression(copy_X=True, fit_intercept=Tr...  1.984488e+01   \n",
       "1   ElasticNet(alpha=0.5, copy_X=True, fit_interce...  2.126031e+01   \n",
       "2   ElasticNet(alpha=0.5, copy_X=True, fit_interce...  2.040441e+01   \n",
       "3   ElasticNet(alpha=0.5, copy_X=True, fit_interce...  1.985613e+01   \n",
       "4   ElasticNet(alpha=0.75, copy_X=True, fit_interc...  2.221879e+01   \n",
       "5   ElasticNet(alpha=0.75, copy_X=True, fit_interc...  2.088021e+01   \n",
       "6   ElasticNet(alpha=0.75, copy_X=True, fit_interc...  1.987007e+01   \n",
       "7   ElasticNet(alpha=1.0, copy_X=True, fit_interce...  2.313768e+01   \n",
       "8   ElasticNet(alpha=1.0, copy_X=True, fit_interce...  2.139897e+01   \n",
       "9   ElasticNet(alpha=1.0, copy_X=True, fit_interce...  1.988953e+01   \n",
       "10  LinearRegression(copy_X=True, fit_intercept=Tr...  7.190229e+13   \n",
       "11  ElasticNet(alpha=0.5, copy_X=True, fit_interce...  2.118860e+01   \n",
       "12  ElasticNet(alpha=0.5, copy_X=True, fit_interce...  2.031463e+01   \n",
       "13  ElasticNet(alpha=0.5, copy_X=True, fit_interce...  1.977227e+01   \n",
       "14  ElasticNet(alpha=0.75, copy_X=True, fit_interc...  2.214457e+01   \n",
       "15  ElasticNet(alpha=0.75, copy_X=True, fit_interc...  2.079269e+01   \n",
       "16  ElasticNet(alpha=0.75, copy_X=True, fit_interc...  1.979403e+01   \n",
       "17  ElasticNet(alpha=1.0, copy_X=True, fit_interce...  2.305430e+01   \n",
       "18  ElasticNet(alpha=1.0, copy_X=True, fit_interce...  2.131282e+01   \n",
       "19  ElasticNet(alpha=1.0, copy_X=True, fit_interce...  1.982448e+01   \n",
       "20  LinearRegression(copy_X=True, fit_intercept=Tr...  6.350138e+13   \n",
       "21  ElasticNet(alpha=0.5, copy_X=True, fit_interce...  2.123782e+01   \n",
       "22  ElasticNet(alpha=0.5, copy_X=True, fit_interce...  2.032999e+01   \n",
       "23  ElasticNet(alpha=0.5, copy_X=True, fit_interce...  1.977227e+01   \n",
       "24  ElasticNet(alpha=0.75, copy_X=True, fit_interc...  2.217338e+01   \n",
       "25  ElasticNet(alpha=0.75, copy_X=True, fit_interc...  2.080951e+01   \n",
       "26  ElasticNet(alpha=0.75, copy_X=True, fit_interc...  1.979403e+01   \n",
       "27  ElasticNet(alpha=1.0, copy_X=True, fit_interce...  2.304178e+01   \n",
       "28  ElasticNet(alpha=1.0, copy_X=True, fit_interce...  2.132340e+01   \n",
       "29  ElasticNet(alpha=1.0, copy_X=True, fit_interce...  1.982448e+01   \n",
       "\n",
       "            wmae  \n",
       "0   1.558057e-01  \n",
       "1   1.826296e-01  \n",
       "2   1.682655e-01  \n",
       "3   1.576113e-01  \n",
       "4   1.982394e-01  \n",
       "5   1.769070e-01  \n",
       "6   1.587910e-01  \n",
       "7   2.130118e-01  \n",
       "8   1.857998e-01  \n",
       "9   1.601693e-01  \n",
       "10  9.004051e+11  \n",
       "11  1.781246e-01  \n",
       "12  1.637479e-01  \n",
       "13  1.539815e-01  \n",
       "14  1.934547e-01  \n",
       "15  1.723273e-01  \n",
       "16  1.550185e-01  \n",
       "17  2.076888e-01  \n",
       "18  1.814250e-01  \n",
       "19  1.566591e-01  \n",
       "20  1.168736e+12  \n",
       "21  1.774894e-01  \n",
       "22  1.629856e-01  \n",
       "23  1.539815e-01  \n",
       "24  1.898834e-01  \n",
       "25  1.701025e-01  \n",
       "26  1.550185e-01  \n",
       "27  2.010951e-01  \n",
       "28  1.775764e-01  \n",
       "29  1.566591e-01  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_wmae(result_dict):\n",
    "    wmae_list = [np.mean(wmae(error_list[0], df)) for error_list in result_dict['errors']]\n",
    "\n",
    "    result_dict['results']['wmae'] = wmae_list\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "linear_results = add_wmae(linear_results)\n",
    "\n",
    "linear_results['results'].to_pickle('linear_results.p')\n",
    "\n",
    "linear_results['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e1a682106b451fa2eb788125da199d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Feature Set', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-362:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hobbs/.conda/envs/ugh/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/hobbs/.local/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/hobbs/.conda/envs/ugh/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a04bff76a4429ba2f5a5df50b42fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Models', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8432edf24cb3487d9f668b16ab254938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Models', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>wmae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dollar_mw ~ opr_hr + week + day + solar_MW + w...</td>\n",
       "      <td>RandomForestRegressor(bootstrap=True, criterio...</td>\n",
       "      <td>7.537054</td>\n",
       "      <td>0.054098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar_mw ~ opr_hr + week + day + solar_MW + w...</td>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>7.466121</td>\n",
       "      <td>0.063105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dollar_mw ~ opr_hr + week + day + solar_MW + w...</td>\n",
       "      <td>RandomForestRegressor(bootstrap=True, criterio...</td>\n",
       "      <td>5.344259</td>\n",
       "      <td>0.025295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dollar_mw ~ opr_hr + week + day + solar_MW + w...</td>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, criterion...</td>\n",
       "      <td>5.267206</td>\n",
       "      <td>0.038049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  \\\n",
       "0  dollar_mw ~ opr_hr + week + day + solar_MW + w...   \n",
       "1  dollar_mw ~ opr_hr + week + day + solar_MW + w...   \n",
       "2  dollar_mw ~ opr_hr + week + day + solar_MW + w...   \n",
       "3  dollar_mw ~ opr_hr + week + day + solar_MW + w...   \n",
       "\n",
       "                                               model     score      wmae  \n",
       "0  RandomForestRegressor(bootstrap=True, criterio...  7.537054  0.054098  \n",
       "1  GradientBoostingRegressor(alpha=0.9, criterion...  7.466121  0.063105  \n",
       "2  RandomForestRegressor(bootstrap=True, criterio...  5.344259  0.025295  \n",
       "3  GradientBoostingRegressor(alpha=0.9, criterion...  5.267206  0.038049  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ideas = ['dollar_mw ~ opr_hr + week + day + solar_MW + wind_MW + temp + latitude + longitude',\n",
    "                 'dollar_mw ~ opr_hr + week + day + solar_MW + wind_MW + latitude + longitude + price_last_hr + price_yesterday + price_last_week']\n",
    "\n",
    "rf = ensemble.RandomForestRegressor(n_jobs = 4)\n",
    "gb = ensemble.GradientBoostingRegressor(max_depth = 10)\n",
    "models = [rf, gb]\n",
    "\n",
    "nonlinear_results = run_models(models, feature_ideas, df)\n",
    "\n",
    "nonlinear_results = add_wmae(nonlinear_results)\n",
    "\n",
    "nonlinear_results['results'].to_pickle('nonlinear_results.p')\n",
    "\n",
    "nonlinear_results['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Now we can test our chosen models on the held-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear:  0.21884839356\n",
      "nonlinear:  0.213111297858\n"
     ]
    }
   ],
   "source": [
    "ols = linear_model.LinearRegression(fit_intercept=True, n_jobs = 3)\n",
    "\n",
    "best_nonlinear_features = 'dollar_mw ~ opr_hr + week + day + solar_MW + wind_MW + latitude + longitude + price_last_hr + price_yesterday + price_last_week'\n",
    "best_linear_features = 'dollar_mw ~ price_last_hr + price_yesterday + price_last_week'\n",
    "\n",
    "# Train on full set\n",
    "def full_train_test(df, features, model):\n",
    "    y, X = patsy.dmatrices(features, data=df, return_type = 'dataframe')\n",
    "    X = preprocessing.scale(X)\n",
    "    fitted = model.fit(X, np.ravel(y))\n",
    "    y_test, X_test = patsy.dmatrices(features, data=df_test, return_type = 'dataframe')\n",
    "    # Save indices from y\n",
    "    index_values = y_test.index\n",
    "    # Calculate y_hats and map to indices\n",
    "    X_test = preprocessing.scale(X_test)\n",
    "    y_hat = pd.DataFrame(data = fitted.predict(X_test), index = index_values)\n",
    "    errors = np.subtract(y_test, y_hat)\n",
    "    return {'model': model, 'rmse': rmse(y_test, y_hat), 'errors': errors}\n",
    "\n",
    "final_linear = full_train_test(df, best_nonlinear_features, ols)\n",
    "final_nonlinear = full_train_test(df, best_nonlinear_features, gb)\n",
    "#final_linear = add_wmae(final_linear)\n",
    "\n",
    "print(\"linear: \", np.mean(wmae(final_linear['errors'], df_test)))\n",
    "print(\"nonlinear: \", np.mean(wmae(final_nonlinear['errors'], df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graphic charts the relationship between temperatures and prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalize = lambda x: (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "avg_price = pd.DataFrame(df[['dollar_mw', 'temp']].groupby(level = 'time').mean())\n",
    "avg_price['time'] = avg_price.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_price[['temp', 'dollar_mw']] = avg_price[['temp', 'dollar_mw']].apply(normalize)\n",
    "\n",
    "ggplot(avg_price, aes(x = 'time')) + \\\n",
    "    geom_line(aes(y = 'dollar_mw')) + \\\n",
    "    geom_line(aes(y = 'temp', color = 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_ideas = ['dollar_mw ~ price_last_hr + price_yesterday + price_last_week']\n",
    "\n",
    "rf = ensemble.RandomForestRegressor(n_jobs = 4)\n",
    "gb = ensemble.GradientBoostingRegressor(max_depth = 10)\n",
    "models = [rf, gb]\n",
    "\n",
    "nonlinear_results = run_models(models, feature_ideas, df)\n",
    "nonlinear_results.to_pickle('new_nonlinear_results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ols = [linear_model.LinearRegression(fit_intercept=False, n_jobs = 3)]\n",
    "\n",
    "#generate a huge list of different elastic nets\n",
    "elastic_nets = [linear_model.ElasticNet(alpha= a, l1_ratio = l, warm_start = True)\n",
    "                for a, l in list(itertools.product(np.linspace(0.5, 1, num = 3), np.linspace(0,1, num = 3)))]\n",
    "\n",
    "feature_ideas = ['dollar_mw ~ C(node)*(price_last_hr + price_yesterday + price_last_week)']\n",
    "\n",
    "linear_results = run_models(ols, feature_ideas, df, folds=4, parallel=True)\n",
    "\n",
    "linear_results.to_pickle('new_linear_results.p')\n",
    "\n",
    "linear_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A single\n",
    "linear_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = 'dollar_mw ~ C(node)*(price_last_hr + price_yesterday + price_last_week)'\n",
    "\n",
    "model = smf.ols(model, data = df)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = 'dollar_mw ~ price_last_hr + price_yesterday + price_last_week'\n",
    "\n",
    "model = smf.ols(model, data = df.loc['ALAMT4G_7_B1'])\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonlinear_results.iloc[0]['errors'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonlinear_results.iloc[0]['errors'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ugh]",
   "language": "python",
   "name": "conda-env-ugh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
